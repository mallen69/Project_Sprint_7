@bentut

###                   Introduction to Survey Design  
##### By Michael NJ Allen


### Develop a Research Proposal First - Then Design the Survey  

##### 1. Be Clear About the Purpose of the Survey & the Research Methodology

##### 2. One or More Research Question(s) Commonly Guide the Conduct and Reporting of the of Research Study

##### 3. Make Hypotheses as Explicit, Clear, and Understandable to a Reader as Possible

##### 4. Research Design (Experimental / Quasi-Experimental / Non-Experimental)

##### 5. Sampling Method  



It can be very tempting to press ahead with designing a survey. But first, be clear about the purpose of the study and the research methodology.  
Research involves systematic investigation of phenomena, the purpose of which could be for:
__Information gathering__ and/or   
__Exploratory:__ e.g., discovering, uncovering, exploring  
__Descriptive:__ e.g., gathering info, describing, summarizing  
__Theory testing__   
__Explanatory:__ e.g., testing and understanding causal relations
__Predictive:__ e.g., predicting what might happen in various scenarios
In the early stages of research projects, brainstorm a series of possible research questions for discussion.
Consider open-ended research questions (e.g., What is the effect of s on t?) and closed-ended questions (e.g., Is u better w?).  
Once research question(s) are established, consider generating hypotheses, which are generally more specific statements to be tested.  
A well-developed research question provides a clear focus for the design and conduct of the study. However it may be necessary to revise the question during the conduct of a study.
Research questions can be written in sentences and paragraphs. They can also be numbered.
Break complicated hypotheses down into sub-hypotheses.  
Each hypothesis should be able to be tested using a single test (or series of related tests).
Hypotheses can be expressed as null and/or alternative hypotheses
Hypotheses can be written in sentences or paragraphs. They can also be numbered.  
Experimental, non-experimental, and quasi-experimental research designs are similar in that all three strategies investigate relationships between variables by comparing groups of scores.  There are also important differences among them.  
The experimental strategy creates the groups by manipulating an independent variable.  
The nonexperimental and quasi-experimental strategies define the groups with a nonmanipulated variable such as a preexisting participant characteristic (e.g., age or gender) or time (e.g., before/after, at age 10 and age 20).    
Quasi-experimental and non-experimental strategies are differentiated by the fact that quasi-experimental studies include some attempt to limit or control threats to internal validity but non-experimental studies do not.    
__Sampling__ is a term used in statistics. It is the process of choosing a representative sample from a target population and collecting data from that sample in order to understand something about the population as a whole.  

[Wiki Survey Design](https://en.wikiversity.org/wiki/Survey_design)


### Survey Content 

##### 1. Make Sure That Every Question Is Necessary

##### 2. Keep it Short and Simple

##### 3. Ask Direct Questions

##### 4. Ask One Question at a Time

##### 5. Avoid Leading and Biased Questions

##### 6. Speak Your Respondent’s Language  



You’re building your survey to obtain important insights, so every question in the survey should play a direct part. It’s best to plan your survey by first identifying the data you need to collect and then writing your questions.
Respondents are less likely to complete long surveys, or surveys that bounce around haphazardly from topic to topic. Therefore, make sure your survey follows a logical order and that it takes a reasonable amount of time to complete
Vague or poorly worded questions confuse respondents and make your data less useful. Strive for clear and precise language that will make your questions easy to answer.
Take a closer look at questions in your survey that contain the word “and”—it can be a red flag that your question has two parts. Here’s a sample: “Which of these cell phone service providers has the best customer support and reliability?” In this case, a respondent may feel that one service is more reliable, but another has better customer support.
Some descriptive words and phrases may interject some bias into your questions, or point the respondent in the direction of a particular answer. In particular, scrutinize adjectives and adverbs in your questions. If they’re not needed, take them out.
Use language and terminology that your respondents will understand. Make words and sentences as simple as possible and avoid technical jargon. However, don’t oversimplify a question to the point that it will change the way the question will be interpreted.  

[Tips For Building Effective Surveys](https://www.qualtrics.com/blog/10-tips-for-building-effective-surveys/)  


### Successful Survey Design  

##### 1. Think before you write: Research Objectives, Attributes, then Questions

##### 2. Design a Good Instrument (Survey / Questionnaire)

##### 3. Question wording

##### 4. Stick to One Major Goal Per Survey – Two to Three Sub-Topics at Most  

##### 5. Question Type and Design

If the first step in your survey project is to start writing questions, you’re off to a bad start. The first step in the questionnaire design process is to review your research objectives from the planning stage and then think about the attributes you want to measure in the survey. 

Attributes are characteristics of whatever it is you’re trying to understand – whether that’s customer, employee or user experience – or whatever. When you’ve identified the attributes of interest, then you can start writing survey questions that generate data to measure those attributes.  

A well-designed instrument, or questionnaire, is a bit of an art. You’re engaged in a balancing act. You want enough comprehensive data for your analysis, but you want to limit ‘respondent burden’. A survey that takes too much energy to complete leads to lower response rates. Keep the burden on the respondent as low as possible, yet enough to achieve your research objectives. As you design the survey, always think about the work you’re asking the respondent to do.   

Keep it short. If you can’t take action on the findings from some question, then why are you asking it?  Make it relevant. Ideally, all the questions in the survey should be relevant to the invitee. That’s hard to achieve 100%, even using branching logic to tailor questions based on how they answer the current question. But lots of irrelevant questions lead to a non-response.  

Design the instrument so respondents are unlikely to make mistakes. For example, a question with a double negative will confuse the respondent, or a poorly presented rating scale could lead the respondent to invert the scale.  

Organize your survey into sections. Topical sections keep the respondent focused on the topic, and make a survey feel shorter. Have a flow across sections that makes sense to the respondent. Don’t rely on open-ended questions. Free-form text questions have their place in a survey to get more granular detail, but over-reliance on this question form introduces respondent burden, administrative burden, and analytical burden. Better to use well-designed closed-ended questions – questions that yield a number or a check as the response – since these questions are far easier for the respondent to answer and for you to analyze.  

The choice of words and phrases in a question is critical in expressing the meaning and intent of the question to the respondent and ensuring that all respondents interpret the question the same way. Even small wording differences can substantially affect the answers people provide.  

Question Type and Design

This type of survey bias includes the selection of different forms of questions (rating scales, ranking, open-ended versus closed-ended) and the options of answers provided to the respondent. The selections made in question types can have significant impact on the responses received. This is also the case for the options researchers provide for participants to choose from.  


### Key Factors When Creating Survey  

##### 1. Mode of Data Collection

##### 2. How You Order Your Questions

##### 3. Accuracy of the Answers You Receive

##### 4. Bias in Self-Reported Behavior

##### 5. Clear Question Structure

##### 6. Visual Survey Design

##### 7. The Importance of Survey Objectives


When you’re gathering data through phone surveys or in-person interviews, the interviewer’s words and actions will have a major impact on your final results. Online surveys, on the other hand, rely heavily on question wording and design.  
You won’t have the benefit of inflection or body language to help convey your questions’ meaning. Phrasing, color choice, and layout will all play major roles in how respondents interpret your questions. Their interpretations will influence your final data.
You won’t have the benefit of inflection or body language to help convey your questions’ meaning. Phrasing, color choice, and layout will all play major roles in how respondents interpret your questions. Their interpretations will influence your final data.  

Each survey question should follow a logical flow. Jumping around from topic to topic may confuse your respondents and cause them to skip questions or abandon the survey altogether. When determining the order of questions within the questionnaire, surveyors must be attentive to how questions early in a questionnaire may have unintended effects on how respondents answer subsequent questions. Researchers have demonstrated that the order in which questions are asked can influence how people respond; earlier questions – in particular those directly preceding other questions – can provide context for the questions that follow (these effects are called “order effects”).  

The order you ask questions matters. Mentioning products, brands, or events can affect how people rate their familiarity and attitudes on subsequent questions. This can be especially harmful in branding and awareness surveys as the mere exposure of a brand name first can influence later questions and findings.  Response options also matter. A respondent might remember a choice that appeared in an earlier question and be more likely to select the response on later questions.  You can often manage many order effects through properly sequenced questions and randomization.  

Even rather benign questions (like asking people their marital status) may prime respondents with negative thoughts as participants recall bad past experiences (like a divorce or death in the family). Moving more sensitive demographic questions and anything that could potentially elicit negative thoughts to the end of a survey when possible may help.  

Most people don’t have a flawless memory. Regardless of their intentions, respondents will not always be able to provide you with accurate information.
For instance, people can answer questions about their gender and age easily, but when it comes to measuring attitudes and opinions, many people have trouble formulating an answer. To get the best possible data about these subjective topics, use language the reflects how your respondents actually think and talk about the topic you’re asking about.  

Generally speaking, people have less precise memories of the mundane behaviors they engage in on a regular basis, and they usually do not mentally categorize events by periods of time (e.g. week, month, year). We should consider appropriate reference periods for the type of behavior we want them to recall. For example, respondents can probably tell you how much time they’ve spent commuting to work this week, but if you ask them how long they commute in a year their recall won’t be as reliable.
Ultimately, questions about measured behavior should be relevant to your respondents and capture their potential state of mind.
Generally speaking, people have less precise memories of the mundane behaviors they engage in on a regular basis, and they usually do not mentally categorize events by periods of time (e.g. week, month, year).  


Survey questions have three distinct parts, and each must work in harmony with the others to capture high quality data. 
These three parts are the question stem (e.g. What is your age?), additional instructions (e.g. Select one answer), and response options (e.g. Under 18, 19-24, 25+). The wrong combination can leave respondents confused about how to answer a question.
Confused respondents lead to confusing survey results.  

The verbal part of your survey is crucial, but if you’re using survey design elements in an inconsistent way can increase the burden on your respondents and prevent them from fully understanding your survey’s meaning.
For example, using different font sizes, colors, and strengths across questions forces the respondent to relearn their meaning each time they’re used. Also, presenting scale questions with different directions (positive to negative on one question, then negative to positive on the next) within the same survey dramatically increases measurement error.
Respondents may assume that all rating questions have the same scale direction even if individual question instructions explain the meaning of the scale’s end points.  

First and foremost, your objectives need to be as specific as possible. A close second place priority: they need to be measurable by an online survey. 
Writing a statement of the overall goal of your survey can be a good place to start if you’re having trouble identifying specific objectives. 
Carefully designing a survey that meets your research objectives can take months.  

[Key Things to Consider for Survey Design](https://www.surveygizmo.com/resources/blog/designing-surveys/)  




### No Matter How Good of a Design - Potential Bias for Survey Data 

##### 1. Knowledgeable Enough to be Attending  
##### 2. Experience / Age / Gender  
##### 3. In a Rush to Complete Survey (Not Built-in Class Time to Complete)  
##### 4. Had a Bad Morning at Home / Hotel that Day  
##### 5. Bad Traffic Day   
##### 6. Not Focused During the Course  
##### 7. Did Not Do the Required Work Throughout the Course  
##### 8. Relationship Issues at Home / Work  
##### 9. Past / Present Working / Personal Relationship with Instructor  
##### 10. Motivation or Lack Thereof  / Forced to Attend  
##### 11. Job Depends on Success of Course Understanding and Completion  
##### 12. Researcher / Survey Designer Bias




http://stattrek.com/statistics/dictionary.aspx?definition=Response%20bias

Response bias refers to the bias that results from problems in the measurement process. Some examples of response bias are given below.

Leading questions. The wording of the question may be loaded in some way to unduly favor one response over another. For example, a satisfaction survey may ask the respondent to indicate where she is satisfied, dissatisfied, or very dissatified. By giving the respondent one response option to express satisfaction and two response options to express dissatisfaction, this survey question is biased toward getting a dissatisfied response.

Social desirability. Most people like to present themselves in a favorable light, so they will be reluctant to admit to unsavory attitudes or illegal activities in a survey, particularly if survey results are not confidential. Instead, their responses may be biased toward what they believe is socially desirable.

https://measuringu.com/survey-biases/

Social Desirability & Conformity

Don’t you agree that recycling is an important initiative for companies to embrace?

Approximately how much time do you spend reading to your children each night?

On average, how much time do you spend planning meals for your family?

If it’s socially acceptable (recycling, reading to kids, or caring for your family), respondents are much more likely to endorse and exaggerate. In additional to socially desirable, a number of studies show people will conform to group norms[pdf] both offline and online.

In fact, it’s hard to convince respondents to go against what’s acceptable even when things are clearly bizarre[pdf]. This means respondents will have a propensity to provide the socially acceptable response over the true response.

Yea Saying and Acquiescing

Do you want your coffee machine to have different profiles?*

Do you use the mail merge feature of Word?

Respondents can tend to be agreeable (acquiesce) and respond usually positively to just about any question you ask them in a survey. One of the best way to minimize this “yea” saying is to minimize simple yes-no answers and instead have respondents select from alternatives or use some type of force choice or ranking.

Note: While a common solution to minimize acquiescent bias is to reverse the tone of items in rating scales, we’ve found, along with other research, that reversing the item wording can actually cause more harm than good in rating scales.


When respondents know where the survey is coming from (the sponsor), it will likely influence responses. If you know the questions about your online social media experience are coming from Facebook, your thoughts and feelings about Facebook will likely impact responses.

This can be especially the case for more ethereal measures like brand attitude and awareness that can be affected from the mere reminder of a brand in the email invitation or name and logo on the welcome page. One of the best ways to minimize sponsorship bias is to obfuscate the sponsor as much as possible and/ or use a third-party research firm (shameless self-promotion).


Asking about gender, race, technical ability, education, or other socio-economic topics may reinforce stereotypes in the mind of the respondents and may even lead them to act in more stereotypical ways. For example, reminding people that stereotypes exist around those who are more technically averse (age), math ability (gender), or intelligence (education level) may affect later responses as the stereotype primes respondents through the questions.

Bias Doesn’t Necessarily Mean Garbage

Just because a survey has bias doesn’t mean the results are meaningless. It does mean you should be able to understand how each may impact your results.

While there’s not a magic cure for finding and removing all biases, being aware of them helps limit their negative impact.


http://fluidsurveys.com/university/avoiding-survey-bias/


Question Type and Design

This type of survey bias includes the selection of different forms of questions (rating scales, ranking, open-ended versus closed-ended) and the options of answers provided to the respondent. The selections made in question types can have significant impact on the responses received. This is also the case for the options researchers provide for participants to choose from.  

To avoid running into this type of bias, it is crucial for the researcher to understand the strengths and weaknesses of each question type they will be using. This way the question and its options will not only be chosen correctly but can be tailored in order to provide only the most useful data. For more information on how to use different question types check out FluidSurveys’s video tutorials.  

One of the most overlooked forms of survey bias comes from poorly designed survey structures. Survey structure usually pertains to the order in which the survey questions are revealed to the respondent, but can also refer to the number of questions per page, the survey logic, the survey length, and the introduction and conclusion. Each of these portions of survey structure can contribute to survey bias and drop outs.

As with the other forms of survey bias, the best way to avoid making errors with your survey structure is through studying how modifying each aspect of your survey will affect your respondents’ reactions to each question. For example, putting the most threatening or personal seeming questions at the end of your survey will decrease your number of drop outs. Acknowledging information like this will allow you to construct the best possible surveys.


https://blog.cruxresearch.com/2013/08/27/the-top-5-errors-and-biases-in-survey-research/

The most important error that creeps into surveys about isn’t statistical at all and is not measurable. The viewpoint of the researcher has a way of creeping into question design and analysis. Some times this is purposeful, and other times it is more subtle. All research designers are human, and have points-of-view. Even the most practiced and professional researchers can have subtle biases in the way they word questions or interpret results. How we frame questions and report results is always affected by our experiences and viewpoints – which can be a good thing, but can also affect the purity of the study.  

### SurveyMonkey's Net Promoter Score (NPS)
insert image:

__The Answers Customers Provide are Classified as Follows:__

__0–6 = Detractors—Unhappy Customers Who Can Hurt Your Brand Through Negative Word-of-Mouth__

__7–8 = Passives—Satisfied but Indifferent Customers Who Could be Swayed by the Competition__

__9–10 = Promoters—Loyal Customers Who Will Keep Buying and Referring Others__  


Want to know how loyal customers are? Curious to learn if your patients recommend you to others? Looking to make sure your clients are happy? Calculate your NPS score by asking “The Ultimate Question.” You’ll learn what your customers think—and a whole lot more.
__Why use NPS?__
When you ask customers the Net Promoter Score question, you’re essentially asking them whether or not they’re taking the time to say positive things about your company or brand. Because when it comes right down to it, word of mouth is everything—especially today, as opinions spread faster via social channels and online forums and reviews.
Finding out your Net Promoter Score is the easiest way to see how your company is doing in the eyes of your customers. Historically, the positive NPS scores have showed strong correlations to profitable growth. Companies and organizations ranging from small start-ups to some of the world’s largest corporations also use the NPS to assess customer satisfaction and track performance.  

[SurveyMonkey Net Promoter Score](https://www.surveymonkey.com/mp/net-promoter-score/)  



### Likert Scale  

##### Example Question:   

##### The Instructor’s Lecture was Delivered Clearly and Effectively

##### Strongly Disagree
##### Disagree
##### Neutral / Neither Agree or Disagree
##### Agree
##### Strongly Agree

##### Likert Scale Keeps the Respondent Focused With Simple and Direct Language

By __definition__ Likert scales are survey questions that offer a range of answer options — from one extreme attitude to another, like “extremely likely” to “not at all likely.” Typically, they include a moderate or neutral midpoint.
Likert scales (named after their creator, American social scientist Rensis Likert) are quite popular because they are one of the most reliable ways to measure opinions, perceptions, and behaviors.
Compared to binary questions, which give you only two answer options, Likert-type questions will get you more granular feedback about whether your product was just “good enough” or (hopefully) “excellent.” They can help decide whether a recent company outing left employees feeling “very satisfied,” “somewhat dissatisfied,” or maybe just neutral.
This method will let you uncover degrees of opinion that could make a real difference in understanding the feedback you’re getting. And it can also pinpoint the areas where you might want to improve your service or product.
When to use a Likert scale questionnaire
Since there are so many kinds of survey questions, how do you know when you should use a Likert scale?
Likert scales are great for digging down deep into one specific topic to find out (in greater detail) what people think about it. So, think of using a Likert scale any time you need to find out more about…
how people are reacting to your new product
what your team thinks about a recent development in the office
how your clients feel about customer service at your company
how successful your public event was with attendees
…or any other questions where you need to measure sentiment about something specific and you want a deeper level of detail in your responses.
If you want to get a bit geeky about it, the deeper level of detail is what survey experts call variance. The more variance you have, the better you know the nuances of someone’s thinking.  
  

[Likert Scale](https://www.surveymonkey.com/mp/likert-scale/)


### And the Most Important Survey Question Is…?  

![](_mallen/Thinking_Girl.jpg)  


Any idea…?


### What Are You Going To Do With the Results…?  

##### Get Your Results in Front of the Decision Makers of the Business in an Understandable Format..!  
##### (Possibly With Calculated Statistical Significance)

![](_mallen/Paper_Work_Overload.jpg)

The most important Survey Question isn’t on the Survey..!  It is what are you going to do with the results…!!




